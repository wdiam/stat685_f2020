---
title: "STAT 685: Dr. Suojin Wang's Group"
subtitle: |
  | Modeling Seoul Bike Sharing Demand
author: "Nam Tran, Bai Zou"
date: \today
header-includes:
   - \usepackage{fontspec}
   - \setmainfont{Times New Roman}
   - \usepackage{setspace}
   - \onehalfspacing
   - \usepackage{enumitem}
   - \usepackage{subfig}
   - \usepackage{url}
   - \usepackage{listings}
   - \usepackage{multirow}
   - \pagenumbering{gobble}
output: 
  pdf_document:
    latex_engine: xelatex
    number_sections: true
    fig_caption: true
    includes:
      in_header: preamble.tex
documentclass: report
fontsize: 12pt
geometry: margin=1in 
urlcolor: blue
---

```{r packages, message=FALSE, echo=FALSE}
rm(list=ls())

knitr::opts_chunk$set(echo = TRUE, fig.height = 3, out.extra = "")

require(tidyverse)
require(dplyr)
require(caret) 
require(glmnet)
require(doParallel)
require(earth)
require(vip)
require(ranger)
require(xgboost)
require(RANN)
require(lubridate)
require(flipTime)
require(e1071)
require(latex2exp)
require(aTSA)
require(forecast)
require(Ckmeans.1d.dp)

theme_update(plot.title = element_text(hjust = 0.5))
```

\newpage

\pagenumbering{roman}
\setcounter{page}{2}
\setcounter{tocdepth}{5}
\setcounter{secnumdepth}{5}

\tableofcontents
\newpage
\listoffigures
\listoftables
\newpage

\pagenumbering{arabic}




\newpage
\chapter{Dependency of $Y_t$}

```{r data_setup_4, cache = TRUE, message=FALSE, echo=FALSE, dependson="packages"}
set.seed(1)

load_data <- function(){
   # Loading the Data
   datPath = paste0(dirname(getwd()), "/data/SeoulBikeData.csv")
   colNames = c("Date", "RentedBikeCount", "Hour", "Temp", "Humidity", 
                "WindSpeed", "Visibility", "DewPointTemp", "SolarRadiation",
                "Rainfall", "Snowfall", "Seasons", "Holiday", "FunctionalDay")
   dat = read_csv(datPath, col_names = colNames, skip=1)
   
   # Setting up Factors
   dat$Hour = as_factor(dat$Hour)
   dat$Seasons = as_factor(dat$Seasons)
   dat$Holiday = as_factor(dat$Holiday)
   dat$FunctionalDay = as_factor(dat$FunctionalDay)
   
   # Creating DateTime that incorporates both Date and Hours and dropping Hour
   dat$Date = AsDateTime(dat$Date) + hours(dat$Hour)
   
   # Identifying qualitative features
   featureLevels = sapply(dat, function(x) { length(unique(x)) })
   qualFeatures = which(featureLevels < 30)

   xQuant = dat %>% select(-all_of(qualFeatures))
   xQual  = dat %>% select(all_of(qualFeatures))
   
   # Creating Dummary Variables 
   ppDummy = dummyVars(~ ., data = xQual, fullRank = TRUE)
   xQualPost = predict(ppDummy, xQual)
   
   datFull = cbind(xQuant, xQualPost)
   
   return (datFull)
}

dat = load_data()

# split into train and test, X and y
split_data <- function(df, anchorDate = "2018/11/01"){
   Xtot = df %>% select(-RentedBikeCount, -Date)
   Ytot = df %>% pull(RentedBikeCount)
   
   # split data into train and test parts by anchor date
   learnNdx = df$Date < anchorDate
   
   y_l = Ytot[learnNdx]
   y_t = Ytot[!learnNdx]
   x_l = Xtot[learnNdx,]
   x_t = Xtot[!learnNdx, ]
      
   xl_FullMat = as.matrix(x_l)
   xt_FullMat = as.matrix(x_t)
   
   colnames(xl_FullMat) <- colnames(Xtot)
   colnames(xt_FullMat) <- colnames(Xtot)
   
   return(list(xlFullMat=xl_FullMat, yl=y_l, xtFullMat=xt_FullMat, yt=y_t))
}

dat_set0 = split_data(df=dat, anchorDate = "2018/11/01")
xlFullMat=dat_set0$xlFullMat
yl=dat_set0$yl
xtFullMat=dat_set0$xtFullMat
yt=dat_set0$yt
```

\section{Autocorrelation and Partial Autocorrelation of Rented Biked Count, $y_t$}

In section 2.2, the ACF and PACF plots are suggesting strong autocorrelation of the past bike demand. The ACF shows a clear daily trend (every 24 lags). The hour feature used in estimators can be used to reflect this daily trend. The PACF shows significant dependence between demand and past demands - lag 1, 2, 3, 4, 5, 8, 9 ,10, etc. However, this past demand information is not well used in previous estimators. A simple way to use the information is to add dependency features of past demand.

```{r yt_acf_pacf2, cache = TRUE, dependson = 'data_setup_4', fig.cap="Autocorrelation and Partial Autocorrelation of Rented Bike Count, i.e., $y_t$", echo=FALSE}
selfACF2  = ggAcf(dat$RentedBikeCount, lag.max = 50) + labs(title=TeX("$y_t$"))
selfPACF2 = ggPacf(dat$RentedBikeCount, lag.max = 50) + labs(title=TeX("$y_t$"))

plots = list(selfACF2, selfPACF2)
gridExtra::grid.arrange(grobs = plots, ncol=2)
```

\section{Dependency Feature}

In addition to weather feature and hour feature, add dependency features for past demand: e.g., lag_1 means demand in the last hour; lag_4 means hourly demand 4 hours ago, etc. By adding dependency features, the top observations will have missing value as past demand information is not available. The obaservation with missing values will be deleted from training data. 

\subsection{Estimation without Dependency Features}

```{r boosting, cache = TRUE, dependson = 'data_setup_4', echo=FALSE, message=FALSE, warning=FALSE}
# cl = makeCluster(6)
# registerDoParallel(cl)
trControl = trainControl(method = "cv", number = 10)

set.seed(1)
tuneGrid = expand.grid("nrounds" = c(750),
                       "max_depth" = c(6, 8),
                       "eta" = c(0.01),
                       "gamma" = 0,
                       "colsample_bytree" = c(0.7),
                       "min_child_weight" = 0,
                       "subsample" = 0.75)

boostOutObjSe = train(x=xlFullMat, y = yl,
                      method="xgbTree",
                      objective="reg:squarederror",
                      tuneGrid = tuneGrid,
                      trControl = trControl)
cal_test_R2 <- function(boost_Out, xtFullM, y_t){
   yhat = predict(boost_Out, xtFullM)
   test_R2 = 1 - sum((yhat - y_t)^2) / sum((y_t - mean(y_t))^2)
   return (test_R2)
}
r2_0 = cal_test_R2(boostOutObjSe, xtFullMat, yt)
```

In previous study, boosting method brings the best result among all estimation methods. Therefore, the estimator using boosting method with parameter tuned from previous study will be used in all following model training and predictions. All observations before anchor date Nov 1, 2018 will are used for training and the 30 observations from Nov 1, 2018 to Nov 30, 2018 are used for testing.
To compare the impact of dependency feature, model $M_0$ is fit with only weather features and hour information. The test $R^2$ in $M_0$ is `r round(r2_0, 3)`. The figure below is showing the feature importance from $M_0$, which suggesting 'Temp' as the most important features effecting the demand. 

```{r boosting_plot, cache = TRUE, dependson = 'boosting', echo=FALSE, fig.cap="Feature Importance $M_0$ "}
importance_matrix = xgb.importance(colnames(xlFullMat), model = boostOutObjSe$finalModel)
xgb.ggplot.importance(importance_matrix, top_n=15)
```


\subsection{Estimation with Dependency Features}

```{r add_lag, cache = TRUE, dependson = 'data_setup_4', echo=FALSE, message=FALSE}
add_lag<-function(lag, df){
   lag_demand = df[1:(dim(df)[1]-lag), 'RentedBikeCount']
   fill_lag = rep(NaN, lag)
   fill_lag = c(fill_lag, lag_demand)
   return(fill_lag)
}

add_past_hour_demand <- function(df, past_hour_vec){
   for (lag_hour in sort(past_hour_vec)){
      col_name = paste0("lag_", lag_hour)
      lag_col = add_lag(lag=lag_hour, df=df)
      df[, col_name] = lag_col
   }
   df = df[complete.cases(df), ]
   return(df)
}
```

```{r boosting1, cache = TRUE, dependson = c('boosting','add_lag'), echo=FALSE, message=FALSE, warning=FALSE}
dat1 = add_past_hour_demand(df=dat, past_hour_vec=c(1,2,3,4,5,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24))
dat_set1 = split_data(df=dat1, anchorDate = "2018/11/01")
xlFullMat1=dat_set1$xlFullMat
yl1=dat_set1$yl
xtFullMat1=dat_set1$xtFullMat
yt1=dat_set1$yt

boostOutObjSe1 = train(x=xlFullMat1, y = yl1,
                      method="xgbTree",
                      objective="reg:squarederror",
                      tuneGrid = tuneGrid,
                      trControl = trControl)
r2_1 = cal_test_R2(boostOutObjSe1, xtFullMat1, yt1)
```

Based on PACF plot, dependency features within 1 day (24 hours) are selected for the model fitting, including the past 1-24 hour demand except for lag 6, 7, 14, as $M_1$. With the additional 21 columns added to X, the test $R^2$ goes up to `r round(r2_1, 3)` - a significant improvement from $M_0$. In addition, the feature importance plot for $M_1$ below shows the past demand features are more important than weather features compared with $M_0$.

```{r boosting_plot1, cache = TRUE, dependson = 'boosting2', echo=FALSE, fig.cap="Feature Importance $M_1$ "}
importance_matrix = xgb.importance(colnames(xlFullMat1), model = boostOutObjSe1$finalModel)
xgb.ggplot.importance(importance_matrix, top_n=15)
```

\subsection{Estimation with Reduced Dependency Features}
```{r boosting2, cache = TRUE, dependson = c('boosting','add_lag'), echo=FALSE, message=FALSE, warning=FALSE}
dat2 = add_past_hour_demand(df=dat, past_hour_vec=c(1,2,11,16,24))
dat_set2 = split_data(df=dat2, anchorDate = "2018/11/01")
xlFullMat2=dat_set2$xlFullMat
yl2=dat_set2$yl
xtFullMat2=dat_set2$xtFullMat
yt2=dat_set2$yt

boostOutObjSe2 = train(x=xlFullMat2, y = yl2,
                      method="xgbTree",
                      objective="reg:squarederror",
                      tuneGrid = tuneGrid,
                      trControl = trControl)
r2_2 = cal_test_R2(boostOutObjSe2, xtFullMat2, yt2)
```

Based on the feature importance plot of $M_1$ and the PACF plot, the dependency features can be reset to lag 1, 2, 11, 16 and 24 to reduce the size of X variables. Thus $M_2$ is fitted with smaller number of dependency features and the test $R^2$ is `r round(r2_2, 3)`, which is less than 1% lower than $M_1$ and significant higher than $M_0$.

\subsection{Estimation with Dependency Features Defined by Business Assumptions}
```{r boosting3, cache = TRUE, dependson = c('boosting','add_lag'), echo=FALSE, message=FALSE, warning=FALSE}
dat3 = add_past_hour_demand(df=dat, past_hour_vec=c(1,2,24,48, 24*7))
dat_set3 = split_data(df=dat3, anchorDate = "2018/11/01")
xlFullMat3=dat_set3$xlFullMat
yl3=dat_set3$yl
xtFullMat3=dat_set3$xtFullMat
yt3=dat_set3$yt

boostOutObjSe3 = train(x=xlFullMat3, y = yl3,
                      method="xgbTree",
                      objective="reg:squarederror",
                      tuneGrid = tuneGrid,
                      trControl = trControl)
r2_3 = cal_test_R2(boostOutObjSe3, xtFullMat3, yt3)
```

In $M_3$, the dependency features added is lag 1, 2, 24, 48 and 24 $\times$ 7 based on business assumptions that the demand is related to the past demands 1 and 2 hours ago, 1 day ago and 1 week ago. The test $R^2$ is `r round(r2_3, 3)`, which is as good as $M_1$ and $M_2$. 

\subsection{Estimation Comparison}

The table below is comparing the test $R^2$ among models with different dependency features. Considering the test accuracy and variable size, $M_2$ and $M_3$ are preferred.

```{r boosting_compare, cache = TRUE, dependson = c('boosting','boosting1', 'boosting2', 'boosting3'), echo=FALSE, message=FALSE}
r2_df = data.frame(Model=c('M0','M1','M2','M3'), TestR2 = round(c(r2_0, r2_1, r2_2, r2_3),3))
rownames(r2_df) <- c('No_Dependency_Feature', 'Full_Dependency_Feature', 'Reduced_Dependency_Feature', 'Business_Dependency_Feature')
knitr::kable(r2_df, caption = "Test R2 Comparison of Models with Different Dependency Features")
```

\newpage
\chapter{Forecasting Application}

\section{Business Scenaros}

The purpose to predict bike demand is to make bikes available and accessible to the public at the right time. Thus, the forecasting of hourly bike demand is required to support business decisions and operations. Based on system infrastructure capacity, we define two typical business scenarios below in real application.

\subsection{Daily Data Update}
The system data is updated on a daily base for further analysis and forecasting to the next 24 hoursâ€™ **hourly demand** is required for high-level planning of the next day. To test the performance in this business scenario, we assume the data is updated at 0:00 AM of the day and all available data at the moment is used for model training to predict the next 24 hour demands.

\subsection{Real-time Data Update}
If the system infrastructure could support real-time data update, an hourly model training could be run to predict the next **hour demand**. Any changes in the past hours could be used in the next hour demand prediction. To test the performance, the models will be trained hourly with all the data available at the moment (include demand data from last hour) and used to predict the demand in the next coming hour.

```{r result_path_setup, cache = TRUE, echo=FALSE}
datPath = paste0(dirname(getwd()), "/data/")
Pred_Hours = seq(AsDateTime("2018/11/01")+hours(0), AsDateTime("2018/11/30")+hours(23), by="hour")
```


\section{Hourly Demand Forecasting with Daily Data Update}

\subsection{Estimator and Dependency Features}

When data is updated once every day, the latest observation available to use as dependency feature is the lag 24 for all prediction time stamps. Therefore, the smallest lag of dependency features can be added is lag 24. Based on the business assumption in dependency feature study, lag 24, 48 and 24 $\times$ 7 are added as dependency features, which represent the past demand from same hour 1 day ago, 2 days ago and 1 week ago. The model training is repeated daily for November 2018. And the forecasting method is boosting using the parameters tuned from previous study. 

\subsection{Forecasting Results}

In a daily data update, there are 30 repeated model training and forecasting (1 in each day). In each iteration of model training and forecasting, all observations prior to the iterator date are used as training data and the next 24 hours' hourly demands are used as testing data. The training $R^2$, mean CV $R^2$ and testing $R^2$ results are recorded in each iteration. 

The table below (see Table \@ref(tab:daily_tab)) shows the average training $R^2$ over the 30 iterations is 97.7% and the average mean CV $R^2$ over the 30 iterations is 79.9%. The low average value and large std value in testing $R^2$ represents some poor prediction accuracy in some of the iterations. This can tell clearly in the figure below comparing forecasted demand and real demand (See Figure \@ref(fig:daily_fig)) - at Date Nov 3, Nov 6 and Nov 9, when there's no demand due to non-functional day, the forecasting at the beginning of the day still predicts certain amount of demand.

The overall forecasting $R^2$ is calculated between all forecasted demand and real demand of the 30 iterations and will be used to compare forecasting accuracy in all scenarios. 

 
```{r daily_tab, cache = TRUE, dependson = "result_path_setup", echo=FALSE}
# read forecasting result daily repeat with auto-corr
read_res_tab <- function(fn){
   res_tab = read.table(paste0(datPath, fn),sep=",", row.names = 1, header = T)
   res_tab['run_time', 'avg'] = res_tab['run_time', 'avg']/3600
   res_tab = res_tab[!row.names(res_tab) %in% "run_time", ]
   colnames(res_tab) <- c("Average", "Std")
   rownames(res_tab) <- c("Train_R2 (per train)", "Mean_CV_R2 (per train)", "Test_R2 (per train)", "Overall_Forecasting_R2")
   return (res_tab)
}
res_daily_corr = read_res_tab("output_daily_cor_sum.csv")
knitr::kable(round(res_daily_corr,3), caption = "Foresting Result with Daily Data Update and Dependency")
```
```{r daily_fig, cache = TRUE, dependson = "result_path_setup", echo=FALSE, fig.cap="Forecasted Demand and Real Demand Comparison with Daily Data Update and Dependency"}
# read forecasting result daily repeat with auto-corr
pred_daily_corr = read.table(paste0(datPath, "output_pred_daily_cor.csv"),sep=",", row.names = 1, header = T)

colors <- c("Real Hourly Demand" = "darkred", "Forecasted Hourly Demand" = "steelblue")
pred_daily_corr %>% 
  ggplot(aes(x=Pred_Hours)) + 
  geom_line(aes(y=Recorded_Y_Test, color = "Real Hourly Demand")) +
  geom_line(aes(y =Predicted_Y_Test, color="Forecasted Hourly Demand"), linetype="twodash") +
  labs(y="Rented Bike Count", x="Date and Hour", color = "") +
  scale_color_manual(values = colors) +
  theme(legend.position="top")
```


\section{Hourly Demand Forecasting with Real-time Data Update}

\subsection{Dependency Features}

When the data is updated in real-time, all past demands up to one hour ago (lag 1) can be used as dependency feature. Therefore, we add the past demand from 1 hour ago, 2 hours ago, 1 day ago and 1 week ago as dependency features to the data ($M_3$ in previous study). The modeling training is repeated every hour and used to predict demand only for the coming hour. And the forecasting method is boosting using the parameters tuned from previous study.  

\subsection{Forecasting Results}

In the real-time data update, there are 30 $\times$ 24 repeated model training and forecasting (1 in each hour). In each iteration of model training and forecasting, all observations prior to the iterator date and hour are used as training data and the next 1 hour demands is used as testing data. As there is only 1 observation in the testing data, testing $R^2$ is not available. 

The table below (see Table \@ref(tab:hourly_tab)) shows both average training $R^2$ and average mean CV $R^2$ over the 30 $\times$ 24 iterations are over 90%. The overall forecasting $R^2$ reaches 96%. And the figure comparing forecasted demand and real demand below (See Figure \@ref(fig:hourly_fig)) shows a very good match between the two curves, representing an accurate prediction. Moreover, with the real-time data update, the system is able to know the latest demand in the past hour and adjust the coming hour demand prediction - forecasted demand in Nov 3, Nov 6 and Nov 9 stays low when detecting low demand in the last hour.

```{r hourly_tab, cache = TRUE, dependson = "daily_tab", echo=FALSE}
# read forecasting result daily repeat with auto-corr
res_hourly_corr = read_res_tab("output_hourly_cor_sum.csv")
knitr::kable(round(res_hourly_corr,3), caption = "Foresting Result with Real-time Data Update and Dependency")
```

```{r hourly_fig, cache = TRUE, dependson = "result_path_setup", echo=FALSE, fig.cap="Forecasted Demand and Real Demand Comparison with Real-time Data Update and Dependency"}
# read forecasting result daily repeat with auto-corr
pred_hourly_corr = read.table(paste0(datPath, "output_pred_hourly_cor.csv"),sep=",", row.names = 1, header = T)

colors <- c("Real Hourly Demand" = "darkred", "Forecasted Hourly Demand" = "steelblue")
pred_hourly_corr %>% 
  ggplot(aes(x=Pred_Hours)) + 
  geom_line(aes(y=Recorded_Y_Test, color = "Real Hourly Demand")) +
  geom_line(aes(y =Predicted_Y_Test, color="Forecasted Hourly Demand"), linetype="twodash") +
  labs(y="Rented Bike Count", x="Date and Hour", color = "") +
  scale_color_manual(values = colors) +
  theme(legend.position="top")
```


\section{Forecasting Results Comparison}

\subsection{Improvement with Real-time Data Update}

If the system could support real-time data update, the overall forecasting $R^2$ shows a 10% improvement (see Table \@ref(tab:compare_tab)). Comparing the forecasted demand to real demand, the real-time data update forecasting shows a much lower discrepancies than the daily data update forecasting (See Figure \@ref(fig:compare_fig) and \@ref(fig:compare_fig1)). 

```{r compare_tab, cache = TRUE, dependson = c("daily_tab", "hourly_tab"), echo=FALSE}
compare_tab = res_daily_corr
colnames(compare_tab) <- c("Daily Data Update with Dependency", "delete")
compare_tab[, "Real-time Data Update with Dependency"] = res_hourly_corr$Average
compare_tab = compare_tab %>% select(-delete)
knitr::kable(round(compare_tab,3), caption = "Forecasting Results Comparison with Dependency")
```

```{r compare_fig, cache = TRUE, dependson = c("daily_fig", "hourly_fig"), echo=FALSE, fig.cap="Forecasted Demand Comparison with Dependency"}
compare_df = pred_daily_corr
colnames(compare_df) = c("pred_daily_corr", "real_demand")
compare_df$pred_hourly_corr = pred_hourly_corr$Predicted_Y_Test

colors <- c("Real Demand" = "darkred", "Daily Data Update Forecasting" = "steelblue", "Real-time Data Update Forecasting" = "green4")

compare_df %>% 
   ggplot(aes(x=Pred_Hours)) + 
   geom_line(aes(y=real_demand, color = "Real Demand")) +
   geom_line(aes(y =pred_daily_corr, color="Daily Data Update Forecasting"), linetype="twodash") +
   geom_line(aes(y =pred_hourly_corr, color="Real-time Data Update Forecasting"), linetype="twodash") +
   labs(y="Rented Bike Count", x="Date and Hour", color = "") +
   scale_color_manual(values = colors) +
   theme(legend.position="top")
```

```{r compare_fig2, cache = TRUE, dependson = "compare_fig", echo=FALSE, fig.cap="Forecasting Residual Comparison with Dependency"}
compare_df %>% 
   ggplot(aes(x=Pred_Hours)) + 
   geom_line(aes(y =pred_daily_corr-real_demand, color="Daily Data Update Forecasting")) +
   geom_line(aes(y =pred_hourly_corr-real_demand, color="Real-time Data Update Forecasting")) +
   labs(y="Forecasting Residuals", x="Date and Hour", color = " ") +
   scale_color_manual(values = colors) +
   theme(legend.position="top")
```

\subsection{Improvement with Dependency}

To better understand the importance of dependency, the same forecasting studies (repeated model training and forecasting on daily base and hourly base) are conducted without dependency features. 

The table below (see Table \@ref(tab:compare_tab2)) shows 8.5% improvement in daily data update and 14.7% improvement in real-time data update in terms of overall forecasting $R^2$. Comparing the two figures plotting forecasting residuals (See Figure \@ref(fig:compare_fig3) and \@ref(fig:compare_fig4)), there's more significant improvement by adding dependency features with real-time data update than the scenario of daily data update - the blue residual line in the second figure is much more smooth than the green line compared with the first figure. 

Moreover, if the system could not support a real-time data update, using the dependency features in the daily data update scenario still brings better (4.3% higher) forecasting accuracy than a real-time data update without dependency. 

```{r compare_tab2, cache = TRUE, dependson = "compare_tab", echo=FALSE}
res_daily_no_corr = read_res_tab("output_daily_no_cor_sum.csv")
res_hourly_no_corr = read_res_tab("output_hourly_no_cor_sum.csv")
compare_tab[, "Daily Data Update without Dependency"] = res_daily_no_corr$Average
compare_tab[, "Real-time Data Update without Dependency"] = res_hourly_no_corr$Average
knitr::kable(round(compare_tab,3), caption = "Forecasting Results Comparison with and without Dependency")
```

```{r compare_fig3, cache = TRUE, dependson = "compare_fig", echo=FALSE, fig.cap="Forecasted Demand Comparison with Daily Data Update"}
pred_daily_no_corr = read.table(paste0(datPath, "output_pred_daily_no_cor.csv"),sep=",", row.names = 1, header = T)
compare_df$pred_daily_no_corr = pred_daily_no_corr$Predicted_Y_Test

colors <- c("Real Hourly Demand" = "darkred", "Forecasting with Dependency" = "steelblue", "Forecasting without Dependency" = "green4")

compare_df %>% 
   ggplot(aes(x=Pred_Hours)) + 
   geom_line(aes(y =pred_daily_corr-real_demand, color="Forecasting with Dependency")) +
   geom_line(aes(y =pred_daily_no_corr-real_demand, color="Forecasting without Dependency"),linetype="twodash") +
   labs(y="Forecasting Residuals", x="Date and Hour", color = "") +
   scale_color_manual(values = colors) +
   theme(legend.position="top") + ylim(-1000, 1000)
```

```{r compare_fig4, cache = TRUE, dependson = "compare_fig", echo=FALSE, fig.cap="Forecasted Demand Comparison with Real-time Data Update"}
pred_hourly_no_corr = read.table(paste0(datPath, "output_pred_hourly_no_cor.csv"),sep=",", row.names = 1, header = T)
compare_df$pred_hourly_no_corr = pred_hourly_no_corr$Predicted_Y_Test

colors <- c("Real Hourly Demand" = "darkred", "Forecasting with Dependency" = "steelblue", "Forecasting without Dependency" = "green4")

compare_df %>% 
   ggplot(aes(x=Pred_Hours)) + 
   geom_line(aes(y =pred_hourly_corr-real_demand, color="Forecasting with Dependency")) +
   geom_line(aes(y =pred_hourly_no_corr-real_demand, color="Forecasting without Dependency"),linetype="twodash") +
   labs(y="Forecasting Residuals", x="Date and Hour", color = "") +
   scale_color_manual(values = colors) +
   theme(legend.position="top") + ylim(-1000, 1000)
```






